<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rmar&#39;s Guide on Rmar&#39;s Guide</title>
    <link>https://dektoud.github.io/blog/</link>
    <description>Recent content in Rmar&#39;s Guide on Rmar&#39;s Guide</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Ryan Martin</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/blog/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AutoReloading PyCall imported Python modules in Julia</title>
      <link>https://dektoud.github.io/blog/post/julia-autoreloading/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://dektoud.github.io/blog/post/julia-autoreloading/</guid>
      <description>

&lt;h2 id=&#34;autoreloading-pycall-imported-modules&#34;&gt;AutoReloading PyCall Imported Modules&lt;/h2&gt;

&lt;p&gt;One of the major components of being productive with my Python workflows was the IPython magic command &lt;code&gt;%autoreload 2&lt;/code&gt;. This magic command throws a hook on the start of running an IPython cell, and recompiles Python modules where source code changes are detected. This is probably the single most useful component of my workflow since I modify and work on packages in Sublime and test and develop the code in an interactive Jupyter notebook. When I first started with PyCall in Julia, I sorely missed this feature. Julia itself offers a sort-of-autoreload for Julia modules using the package &lt;code&gt;ClobberingReload.jl&lt;/code&gt;. Although this (mostly) works for the Julia packages, any changed Python source code is omitted. To add this functionality to &lt;code&gt;PyCall.jl&lt;/code&gt;, I did some digging through IPython to figure out how Python does it and how it can be replicated for PyCall loaded modules in Julia.&lt;/p&gt;

&lt;p&gt;The first component is to generate a new class that mimics what is being done by the IPython Magic reloader:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.extensions.autoreload import ModuleReloader
import sys

class PyReloader:
    &amp;quot;&amp;quot;&amp;quot;
    Class pretty well taken directly from the IPython %autoreload magic function..
    very untested..
    &amp;quot;&amp;quot;&amp;quot;
    def __init__(self):
        self.mr = ModuleReloader()
        self.mr.enabled = True
        self.mr.check_all = True
        self.mr.check()
        self.loaded_modules = set(sys.modules)

    def reload(self):
        self.mr.check()
        self.reload_step2()

    def reload_step2(self):
        newly_loaded_modules = set(sys.modules) - self.loaded_modules
        for modname in newly_loaded_modules:
            _, pymtime = self.mr.filename_and_mtime(sys.modules[modname])
            if pymtime is not None:
                self.mr.modules_mtimes[modname] = pymtime
        self.loaded_modules.update(newly_loaded_modules)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, it should be loaded in Julia with PyCall, and made to run before each IJulia cell using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using IJulia: push_preexecute_hook
using PyCall
@pyimport rmutils.jlutils.pyreimport as prl
pyreloader = prl.PyReloader()
push_preexecute_hook(() -&amp;gt; pyreloader[:reload]())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now in an interactive Julia session, if Python code is loaded using PyCall, and modified, it will be automatically reloaded as if &lt;code&gt;%autoreload 2&lt;/code&gt; was working in the background!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transitioning from Python to Julia</title>
      <link>https://dektoud.github.io/blog/post/julia/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://dektoud.github.io/blog/post/julia/</guid>
      <description>

&lt;h2 id=&#34;two-languages&#34;&gt;Two Languages&lt;/h2&gt;

&lt;p&gt;Python suffers from a two language problem. On one end the syntax, vast and mature library ecosystem, dynamic style and interactive workflows that Python offers provide a flexible and productive prototyping environment for new ideas. However, when moving past initial ideas and beginning to apply those ideas to datasets of meaningful size, &lt;em&gt;pythonistas&lt;/em&gt; often look to things like &lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/&#34; target=&#34;_blank&#34;&gt;Cython, Numba, F2PY or C++&lt;/a&gt; to gain additional performance. In my research group we spend much of our time developing and implementing ideas using Python (or Matlab), and once those ideas are demonstrated, often a follow-up Fortran implementation is generated so that statically compiled executables implementing those ideas can reach as wide an audience as possible. Thus, to be successful we are required to work with some high-level and dynamic language and also some secondary language that can speed up the implementation and be compiled to a static executable for distribution. This two language problem is a common &lt;code&gt;pain point&lt;/code&gt; for numerical computing in Python.&lt;/p&gt;

&lt;h2 id=&#34;the-motivation&#34;&gt;The Motivation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt; claims to offer a fundamentally new paradigm targeting this problem. This language is tailored to numerical computing by offering a dynamic programming environment and static type definitions with JIT-compilation to within 1-2x the performance compiled languages (Fortran, C). Thus it is easy to see just why Julia is so appealing: fast development times with dynamic and interactive programming; seemingly painless code optimization using static typing and an LLVM compiler that gets speeds in the ballpark of compiled languages; and as a final perk to the language, a glimmer of hope that static compilation may one day be a standard part of the language.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# dynamic containers
list = Any[]
# iteration
for item in items
    push!(list, item)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;really-switching&#34;&gt;Really Switching?&lt;/h2&gt;

&lt;p&gt;One of the larger hurdles for actually switching from Python is the fact that I have developed a large suite of utilities that I depend on in my scripting and research workflows. One of those components is F2PY, which I use to write fast-running custom loops. I am hoping that Julia fills the requirements of fast-running code going forward.. but one important point of concern is losing all the utilities that I have worked so hard on in the past. Luckily a package &lt;code&gt;PyCall.jl&lt;/code&gt; allows Julia to interact directly with Python code. The syntax is a bit strange but a Python call like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pygeostat as gs
import numpy as np

x = np.random.randn(100)
y = np.random.randn(100)

ax = gs.scatxval(x, y)
# and to modify properties, e.g.:
ax.set_ylim([-4, 4])
ax.set_xlim([-4, 4])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;turns into this when called from Julia:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using PyCall
@pyimport pygeostat as gs

x = randn(100)  # Julia includes this by default
y = randn(100)

ax = gs.scatxval(x, y)
ax[:set_ylim]([-4, 4])
ax[:set_xlim]([-4, 4])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note the similarity of the calls to the &lt;code&gt;scatxval()&lt;/code&gt; function. A large number of standard Python types are interoperable. One potential concern is the use of &lt;code&gt;pd.DataFrames()&lt;/code&gt; in Python versus the DataFrames in Julia.. but much of that concern can be alleviated by using Arrays which PyCall automates the type conversion back and forth between the Julia and Python objects. Infact, an entire Python-based workflow can be generated using existing scripts and tools developed in Python. Thus, any researcher who depends largely on Python can rest easy that their hard work will still aid them as they venture out to learn Julia.&lt;/p&gt;

&lt;h2 id=&#34;quick-speed-demo&#34;&gt;Quick Speed Demo&lt;/h2&gt;

&lt;p&gt;In my &lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt; I demonstrated a number of methods to improve the speed of a naive triple loop implementation of a gradient calculation for a 3-dimensional array. A similar implementation using the same triple-loop strategy in Julia is shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot; calculate the forward-reverse diffs on the 3D array&amp;quot;
function gridgradients(a)
    nx, ny, nz = size(a)
    gx = zeros(a)
    gy = zeros(a)
    gz = zeros(a)
    for k in 1:nz
        for j in 1:ny
            for i in 1:nx
                is = max(1, i - 1)
                ie = min(nx, i + 1)
                js = max(1, j - 1)
                je = min(nx, j + 1)
                ks = max(1, k - 1)
                ke = min(nx, k + 1)
                gx[i, j, k] = a[ie, j, k] - a[is, j, k]
                gy[i, j, k] = a[i, je, k] - a[i, js, k]
                gz[i, j, k] = a[i, j, ke] - a[i, j, ks]
            end
        end
    end
    return gx, gy, gz
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Over 1000 iterations, this function averages $1.13ms$, which is ~1.5x the speed of Fortran or Cython, and almost 2x the speed of Numba with no additional decorations or work on my behalf. Note that the arrays are $1$ indexed, and the ordering of the fastest axis is familiar as it is the same as Fortran and the opposite of C and Python. The speedup here over pure Python is immense for code generated with similar effort.&lt;/p&gt;

&lt;p&gt;Recalling one of the optimizations that we chose in Cython:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@cython.boundscheck(False)
@cython.wraparound(False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A similar optimization is immediately available in the Julia code with the &lt;code&gt;@inbounds&lt;/code&gt; macro, which simply disables bounds-checks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;gt;?@inbounds
@inbounds(blk)

Eliminates array bounds checking within expressions.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;&amp;quot; calculate the forward-reverse diffs on the 3D array&amp;quot;
function gridgradients_inbounds(a)
    nx, ny, nz = size(a)
    gx = zeros(a)
    gy = zeros(a)
    gz = zeros(a)
    @inbounds for k in 1:nz
        @inbounds for j in 1:ny
            @inbounds for i in 1:nx
                is = max(1, i - 1)
                ie = min(nx, i + 1)
                js = max(1, j - 1)
                je = min(nx, j + 1)
                ks = max(1, k - 1)
                ke = min(nx, k + 1)
                gx[i, j, k] = a[ie, j, k] - a[is, j, k]
                gy[i, j, k] = a[i, je, k] - a[i, js, k]
                gz[i, j, k] = a[i, j, ke] - a[i, j, ks]
            end
        end
    end
    return gx, gy, gz
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this modified code runs in $0.67ms$ averaged over 1000 iterations. In other words, we are faster than both Cython and Fortran, and very close to Numba, and the syntax and complexity of the code hasn&amp;rsquo;t changed dramatically. The other touted benefit to the user (which I am still trying to wrap my head around as I learn more about Julia) is that all user defined types are statically compiled, so if &lt;code&gt;a&lt;/code&gt; was a matrix of:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;type MyFloat &amp;lt;: Real
    xi::Float64
    yi::Float64
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and certain methods are properly overloaded to make &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; work correctly, the code using that custom type &lt;em&gt;would be as fast as&lt;/em&gt; that using the native types from the loops above.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;I am very new to Julia. The type system is familiar since Fortran had a form of multiple dispatch by defining function interfaces. Static typing is familiar, plotting is available using existing Python libraries. Static compiling to exe remains to be seen. Going forward I expect to carry out all work in Julia in hopes of finally dropping Fortran as my speed crutch.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Iterative refinement of implicit boundary models for improved geological feature reproduction</title>
      <link>https://dektoud.github.io/blog/publication/geological-features/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://dektoud.github.io/blog/publication/geological-features/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Methods to write fast subroutines for Python - minimal computer science required</title>
      <link>https://dektoud.github.io/blog/post/fast_subroutines/</link>
      <pubDate>Tue, 07 Feb 2017 21:00:01 -0700</pubDate>
      
      <guid>https://dektoud.github.io/blog/post/fast_subroutines/</guid>
      <description>

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: I am not a Python or programming expert. There are probably better ways to optimize subroutines, but that is not the point of this post!.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Python is an impressive programming language for a beginning programmer/scientist. Syntax is easy to learn, the language is expressive (in the sense that it reads like it is doing things), and there are immense guides out there on the web to learn nearly any aspect of Python you can think of. I do not profess to be an expert of Python, by any means. I am self taught and know enough to make things happen for my research. I know (generally and definitely not enough) about the standard libraries, and I know enough about what &lt;em&gt;I want&lt;/em&gt; to happen in my code that I can find libraries meaningful for my research, i.e. numpy matrix manipulations, sparse linear algebra and sklearn machine learning algorithms.&lt;/p&gt;

&lt;p&gt;However, as with any research project, you are on the cutting edge and sometimes functions you require are not implemented in standard packages, or you require access to specific portions of the functions to insert new ideas. Our research group is historically invested in Fortran, so naturally, new code is written in Fortran to leverage the vast library of existing codes. Many libraries can be used within Fortran, however, its commonly easier to prototype and test outside of Fortran.&lt;/p&gt;

&lt;h1 id=&#34;methods-for-fast-computations-in-python&#34;&gt;Methods for &lt;em&gt;FAST&lt;/em&gt; computations in Python&lt;/h1&gt;

&lt;p&gt;Keeping in mind that we are at the cutting edge and need to develop fast subroutines for complicated numerical analyses, and also that our definition of &lt;strong&gt;&lt;em&gt;fast&lt;/em&gt;&lt;/strong&gt; is to execute numerical calculations in the least amount of time (as opposed to querying databases or other non-numerical tasks), what are the ways that we can do this within our chosen Python scripting universe? Anyone who has traveled down this road is likely familiar with the major options, and there are benefits and drawbacks to each of them. It depends on the application, complexity of the code, and the intended use of the code. I am focused on numerical computations in my research using linear algebra, matrix solvers, and machine learning techniques. Since my research group primarily produces the standalone Fortran executables, &lt;a href=&#34;https://docs.scipy.org/doc/numpy-dev/f2py/&#34; target=&#34;_blank&#34;&gt;F2PY&lt;/a&gt; project is attractive for mixing Python and Fortran code. There are other methods to call Fortran code from Python, too, like &lt;a href=&#34;https://docs.python.org/3.5/library/ctypes.html&#34; target=&#34;_blank&#34;&gt;ctypes&lt;/a&gt; or a library called &lt;a href=&#34;http://cffi.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;cffi&lt;/a&gt;. However, all of these methods require fairly polished and working Fortran code that can be compiled and runs with minimal and easy to trace errors. This may not be completely suitable for speeding up research code since tracking down and fixing errors is difficult, especially for the newcomer. Compiling the code can be a headache in itself, especially if you are working on windows (which I am). As a beginning programmer and researcher learning about designing algorithms I guarantee that the flexibility in debugging and testing out subroutines that Python provides will improve the development of your ideas.&lt;/p&gt;

&lt;p&gt;A number of projects address the need for fast Python subroutines, like &lt;a href=&#34;http://www.numpy.org/&#34; target=&#34;_blank&#34;&gt;Numpy&lt;/a&gt;, &lt;a href=&#34;http://pypy.org/&#34; target=&#34;_blank&#34;&gt;PyPy&lt;/a&gt;,  &lt;a href=&#34;http://numba.pydata.org/&#34; target=&#34;_blank&#34;&gt;Numba&lt;/a&gt;, &lt;a href=&#34;http://cython.org/&#34; target=&#34;_blank&#34;&gt;Cython&lt;/a&gt;, and many many many others&amp;hellip;. I&amp;rsquo;m sure. So, for the beginning researcher? Which methodology provides the most benefit with the least amount of investment? I will focus on the following mainly because they are the ones that I have tried:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/#F2PY&#34; target=&#34;_blank&#34;&gt;F2PY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/#numpy&#34; target=&#34;_blank&#34;&gt;Numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/#numba&#34; target=&#34;_blank&#34;&gt;Numba&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dektoud.github.io/blog/post/fast_subroutines/#cython&#34; target=&#34;_blank&#34;&gt;Cython&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each of the above methods attacks the problem in different ways. F2PY lets you compile Fortran code into easily callable python modules. Numpy provides a vast library of numerical computation functions that might allow you to skip the lower level languages all together. Numba uses &amp;lsquo;just in time&amp;rsquo; (JIT) compiling to &amp;lsquo;compile&amp;rsquo; native python code. This can be advantageous when the code consists of a number of loops with relatively simple mathematical operations. And finally Cython allows you to write static-typed &amp;lsquo;Python&amp;rsquo; that is compiled to C++ and taken to the extreme using Cython would allow you to write an entire project essentially in C++.&lt;/p&gt;

&lt;h1 id=&#34;example&#34;&gt;Example where fast code is needed&lt;/h1&gt;

&lt;p&gt;Lets consider an example of computing the gradients on a 3D grid using the forward-reverse difference at each cell. Assume that we don&amp;rsquo;t have any knowledge about specialized libraries that have already implemented this feature. Lets also assume that writing out the code in loop-format benefits our research so we can add in some ad-hoc calculations in the grid that &lt;em&gt;couldn&amp;rsquo;t&lt;/em&gt; be handled if we used an existing package to get the gradients, or if we used vectorized code (which Python is very good at).&lt;/p&gt;

&lt;h2 id=&#34;testing-the-code&#34;&gt;Testing the Code&lt;/h2&gt;

&lt;p&gt;I run Python 3.5 from Anaconda usually in the Jupyter notebook. A magic cell prefixed with &lt;code&gt;%time&lt;/code&gt; or &lt;code&gt;%%timeit&lt;/code&gt; &lt;em&gt;should&lt;/em&gt; be available to time functions, but these have never worked for me. Therefore I am using the following to test the functions implemented in this document:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
def timefunc(function, args, n=100):
    stime = time.time()
    for _ in range(n):
        function(*args)
    return &#39;Time per iteration %.9f&#39; % ((time.time() - stime) / float(n))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and tested with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def function ():
    return &#39;this is the function &#39;

print(timefunc(function, arguments))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The test data is constant between runs, and generated using numpy:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
grid = np.random.rand(50, 50, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;python-only&#34;&gt;Python Only&lt;/h1&gt;

&lt;p&gt;Lets start with un-vectorized Python code using loops (pretty much the worst case and something that should never be done in Python, but hey, we&amp;rsquo;re learning):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

def calc_gradients(grid):
    nx, ny, nz = np.shape(grid)  # assumes the grid is 3D
    gx = np.zeros((nx, ny, nz))
    gy = np.zeros((nx, ny, nz))
    gz = np.zeros((nx, ny, nz))
    # the dreaded triple loop, a naive python implementation
    for i in range(nx):
        for j in range(ny):
            for k in range(nz):
                # limit the array indexes, remember about Python 0-indexing
                ist = max([0, i - 1])
                jst = max([0, j - 1])
                kst = max([0, k - 1])
                ifn = min([nx - 1, i + 1])
                jfn = min([ny - 1, j + 1])
                kfn = min([nz - 1, k + 1])
                # calculate the gradients
                gx[i, j, k] = ( grid[ist, j, k] - grid[ifn, j, k] ) / 2.0
                gy[i, j, k] = ( grid[i, jst, k] - grid[i, jfn, k] ) / 2.0
                gz[i, j, k] = ( grid[i, j, kst] - grid[i, j, kfn] ) / 2.0
    return gx, gy, gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which takes $0.365s$ per iteration. This isnt terribly bad. Some time is saved by using the standard library &lt;code&gt;max()&lt;/code&gt; function instead of the numpy &lt;code&gt;np.maximum()&lt;/code&gt; function.&lt;/p&gt;

&lt;h1 id=&#34;numba&#34;&gt;Numba&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://numba.pydata.org/&#34; target=&#34;_blank&#34;&gt;Numba&lt;/a&gt;, the JIT compiler, at a very high level takes Python code and makes machine code that runs very fast. Recent versions of Numba support many Numpy functions (you can &lt;a href=&#34;http://numba.pydata.org/&#34; target=&#34;_blank&#34;&gt;check it out here&lt;/a&gt;). To my knowledge, this is the simplest way to speed up this type of triple loop happening in Python. A simple decorator &lt;code&gt;@numba.jit&lt;/code&gt; placed at the start of the function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numba
import numpy as np

@numba.jit
def calc_gradients_jit(grid):
    nx, ny, nz = np.shape(grid)  # assumes the grid is 3D
    gx = np.zeros((nx, ny, nz))
    gy = np.zeros((nx, ny, nz))
    gz = np.zeros((nx, ny, nz))
    # the dreaded triple loop, a naive python implementation
    for i in range(nx):
        for j in range(ny):
            for k in range(nz):
                # limit the array indexes, remember about Python 0-indexing
                ist = max(0, i - 1)
                jst = max(0, j - 1)
                kst = max(0, k - 1)
                ifn = min(nx - 1, i + 1)
                jfn = min(ny - 1, j + 1)
                kfn = min(nz - 1, k + 1)
                # calculate the gradients
                gx[i, j, k] = ( grid[ist, j, k] - grid[ifn, j, k] ) / 2.0
                gy[i, j, k] = ( grid[i, jst, k] - grid[i, jfn, k] ) / 2.0
                gz[i, j, k] = ( grid[i, j, kst] - grid[i, j, kfn] ) / 2.0
    return gx, gy, gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the function runs in $0.695ms$, or about $525x$ faster average over 1000 iterations. Unfortunately if things outside of simple mathematical operations are required, and those are unsupported within the set of functions converted from Numpy (or other libraries) to standard Python implementations specifically for Numba, then you&amp;rsquo;re stuck implementing them on your own. So, this can&amp;rsquo;t be used for everything. But in this simple case, it is the best!&lt;/p&gt;

&lt;h1 id=&#34;cython&#34;&gt;Cython&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://cython.org/&#34; target=&#34;_blank&#34;&gt;Cython&lt;/a&gt; is a nice library that essentially lets you write compiled C extensions with familiar Python-like syntax. Speed comes from declaring static types with specialized code. Cython is essentially its own syntax although many things are similar to Python or C (although I have never used the latter). The Cython code is converted to C using all sorts of trickery that isn&amp;rsquo;t important at this level of understanding, and the result is an extension module that can be imported and called from Python, and has all the speed of a compiled language. I think Cython can be quite flexible, but the most speed comes from being explicit and defining the types of all variables that are used in the code. Special syntax is required for this part which can be a bit confusing to learn, but there are lots of examples out there. So, our 3D gradient subroutine becomes (using the Cython magic cell):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%cython
import numpy as np
cimport numpy as np
cimport cython

@cython.boundscheck(False) # these flags may make problems..
@cython.wraparound(False)
def calc_gradients_cy(np.ndarray[np.double_t, ndim=3] grid):
    # explicitly define ***ALL*** variables types
    cdef int nx = grid.shape[0]
    cdef int ny = grid.shape[1]
    cdef int nz = grid.shape[2]
    cdef int i, j, k, ist, jst, kst, ifn, jfn, kfn
    cdef np.ndarray[np.double_t, ndim=3] gx = np.zeros((nx, ny, nz), dtype=np.double)
    cdef np.ndarray[np.double_t, ndim=3] gy = np.zeros((nx, ny, nz), dtype=np.double)
    cdef np.ndarray[np.double_t, ndim=3] gz = np.zeros((nx, ny, nz), dtype=np.double)

    # the dreaded triple loop, a naive python implementation
    for i in range(nx):
        for j in range(ny):
            for k in range(nz):
                # limit the array indexes, remember about Python 0-indexing
                ist = max(0, i - 1)
                jst = max(0, j - 1)
                kst = max(0, k - 1)
                ifn = min(nx - 1, i + 1)
                jfn = min(ny - 1, j + 1)
                kfn = min(nz - 1, k + 1)
                # calculate the gradients
                gx[i, j, k] = ( grid[ist, j, k] - grid[ifn, j, k] ) / 2.0
                gy[i, j, k] = ( grid[i, jst, k] - grid[i, jfn, k] ) / 2.0
                gz[i, j, k] = ( grid[i, j, kst] - grid[i, j, kfn] ) / 2.0
    return gx, gy, gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function comes in slightly behind Numba at $0.953ms$ average over 1000 iterations, which is a $383x$ speedup. However, this comes at a cost of much more complex conversion of the original code to statically type everything. Additionally, there are likely Cython best practice conventions that I have not considered, and therefore the above code may be suboptimal.&lt;/p&gt;

&lt;h1 id=&#34;F2PY&#34;&gt;F2PY&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-dev/f2py/&#34; target=&#34;_blank&#34;&gt;F2PY&lt;/a&gt; is my favorite methodology to compile fast code, but this is because: 1) my research group uses Fortran, 2) I know Fortran, and 3) I have mastered F2PY on Windows with the Intel Compiler. This method is definitely not where I would start if I am learning. Many people view Fortran as an ancient language not worth learning. I agree that prototyping code and ideas in Fortran can be arduous, but the open source GSLIB programs released in the 90&amp;rsquo;s, which are still relevant, pretty well sum up how useful Fortran can be. Distributing static executables allows you to reach a wider audience than Python which is notoriously hard to distribute on Windows to people who don&amp;rsquo;t use Python.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-fortran&#34;&gt;subroutine calc_gradients(nx, ny, nz, grid, gx, gy, gz)
  implicit none
  integer, intent(in) :: nx, ny, nz
  real*8, intent(in) :: grid(nx, ny, nz)
  real*8, intent(out) :: gx(nx, ny, nz), gy(nx, ny, nz), gz(nx, ny, nz)
  integer :: i, j, k, ist, jst, kst, ifn, jfn, kfn
  ! triple loop, reverse fastest axes
  do k = 1, nz
    do j = 1, ny
      do i = 1, nx
        ! ensure the indices do not go out of bounds
        ist = max(1, i - 1)
        jst = max(1, j - 1)
        kst = max(1, k - 1)
        ifn = min(nx, i + 1)
        jfn = min(ny, j + 1)
        kfn = min(nz, k + 1)
        ! calculate each gradient
        gx(i, j, k) = ( grid(ist, j, k) - grid(ifn, j, k) ) / 2.0D0
        gy(i, j, k) = ( grid(i, jst, k) - grid(i, jfn, k) ) / 2.0D0
        gz(i, j, k) = ( grid(i, j, kst) - grid(i, j, kfn) ) / 2.0D0
      enddo
    enddo
  enddo
end subroutine calc_gradients
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function runs in roughly the same amount of time as Cython at $0.993ms$ average over 1000 iterations, which is a $367x$ speedup. However, this is a totally different language and if you need to change the code and recompile the function with F2PY, you have to restart the kernel in order to reimport the modified Fortran extension, which ends up loosing you some efficiency in the long run. This method is extremely useful if your end use case is to deploy with Fortran executables, of if you want to leverage some ancient Fortran library that isn&amp;rsquo;t already wrapped for Python. However, it&amp;rsquo;s hard to recommend this method for newcomers since the other methods are simpler to get fast code going.&lt;/p&gt;

&lt;p&gt;The common issue with linking Fortran to Python (mainly for Windows users) is with F2PY. Depending on the version of Python, Fortran compiler, and platform, this can either be a breeze, or a complete pain. If you are having some issues in Windows, you can check out the &lt;a href=&#34;http://www.ccgalberta.com/pygeostat/fortran.html&#34; target=&#34;_blank&#34;&gt;pygeostat documentation on Fortran in Python&lt;/a&gt; for some examples on common errors and some suggested solutions. Typically the fact of running Windows is the single greatest hurdle to using F2PY for this workflow. Luckily &lt;a href=&#34;http://www.ccgalberta.com/pygeostat&#34; target=&#34;_blank&#34;&gt;pygeostat&lt;/a&gt; has taken care of the hard work and implements a custom F2PY compiling script for Windows that works across several versions of Python and with Intel and GNU Fortran compilers.&lt;/p&gt;

&lt;h1 id=&#34;numpy&#34;&gt;So, what about straight up Numpy?&lt;/h1&gt;

&lt;p&gt;Of course, for a task such as computing the gradients on the grid (this is a very common task), Numpy and its vast library of computational functions should probably be investigated. A quick Google search for &lt;code&gt;&#39;numpy gradients&#39;&lt;/code&gt; returns the &lt;a href=&#34;https://docs.scipy.org/doc/numpy/reference/generated/numpy.gradient.html&#34; target=&#34;_blank&#34;&gt;numpy.gradient&lt;/a&gt; function which can be used to quickly compute the gradients of the 3D grid. The implementation is simple:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from numpy import gradient

gradient(grid)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The numpy gradient function runs only a little bit slower than Cython and Fortran at $2.50ms$ averaged over 1000 iterations, which is a $146x$ speedup. Unfortunately, since we offload the numerical component of the calculation, we loose access to the portion of the subroutine that we wanted, to inject some custom code at each cell.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;There are a variety of methods to make subroutines run faster in Python. The best way to prototype new ideas is definitely to &lt;em&gt;NOT&lt;/em&gt; write research code in Fortran, rather use some mixed Python-Speed methodology as outlined above to develop ideas quickly while writing readable and quickly modifiable code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dektoud.github.io/blog/license/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dektoud.github.io/blog/license/</guid>
      <description>&lt;p&gt;All content included on this site unless otherwise attributed ownership is subject to the following license:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Copyright (c) 2017 Ryan Martin

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &amp;quot;Software&amp;quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &amp;quot;AS IS&amp;quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
